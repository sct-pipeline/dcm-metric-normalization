#
# The script compute correlation between DCM hyperintensity lesion volume obtained using sct_analyze_lesion and
# normalized metrics obtained using sct_compute_compression for the dcm-zurich-lesions dataset
#
# Author: Jan Valosek, Sandrine Bédard
#

import os
import argparse

import matplotlib.pyplot as plt
import pandas as pd
import logging
import sys
import numpy as np
from sklearn.linear_model import LinearRegression


FNAME_LOG = 'log_stats.txt'
# Initialize logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)  # default: logging.DEBUG, logging.INFO
hdlr = logging.StreamHandler(sys.stdout)
logging.root.addHandler(hdlr)

metrics = [
    'area',
    'diameter_AP',
    'diameter_RL',
    'eccentricity',
    'solidity'
]

METRIC_TO_AXIS = {
    'diameter_AP': 'AP Diameter [mm]',
    'area': 'Cross-Sectional Area [mm²]',
    'diameter_RL': 'RL Diameter [mm]',
    'eccentricity': 'Eccentricity [%]',
    'solidity': 'Solidity [%]'
}

# Some subjects have more than one compression --> use the compression level where the lesion is presented
compression_slice = {
    'sub-14': 14,
    'sub-15': 7,
    'sub-16': 16,
}

metrics_ratio = [metric + '_ratio' for metric in metrics]
metrics_ratio_norm = ['normalized_' + metric + '_ratio' for metric in metrics]


class SmartFormatter(argparse.HelpFormatter):

    def _split_lines(self, text, width):
        if text.startswith('R|'):
            return text[2:].splitlines()
        # this is the RawTextHelpFormatter._split_lines
        return argparse.HelpFormatter._split_lines(self, text, width)


def get_parser():
    parser = argparse.ArgumentParser(
        description="The script compute correlation between DCM hyperintensity lesion volume obtained using "
                    "sct_analyze_lesion and normalized metrics obtained using sct_compute_compression for the "
                    "dcm-zurich-lesions dataset",
        formatter_class=SmartFormatter
    )
    parser.add_argument(
        '-path-results',
        required=True,
        metavar='<file_path>',
        help="Path to results folder.")
    parser.add_argument(
        '-path-data-processed',
        required=True,
        metavar='<file_path>',
        help="Path to data_processed folder.")
    parser.add_argument(
        '-path-out',
        required=False,
        default=os.path.join(os.getcwd(), 'metrics_vs_lesion_volume'),
        metavar='<file_path>',
        help="Path where results will be saved.")
    return parser


def compute_regression(x, y):
    """
    Compute a linear regression between x and y:
    y = Slope * x + Intercept
    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html

    You can then plot the linear fit by
    ax.plot(x_vals, y_vals, '--', color='red')

    :param x: ndarray: input - regressor
    :param y: ndarray: output - response
    :return: intercept: ndarray: intercept constant (bias term)
    :return: slope: ndarray: slope
    :return: reg_predictor: ndarray:
    :return: r2_sc: float: coefficient of determination
    :return x_vals: ndarray: x values for the linear fit plot
    :return y_vals: ndarray: y values for the linear fit plot
    """
    # Make sure we are working with numpy arrays
    if isinstance(x, pd.Series):
        x = x.to_numpy()
    if isinstance(y, pd.Series):
        y = y.to_numpy()

    # Create an instance of the class LinearRegression, which will represent the regression model
    linear_regression = LinearRegression()
    # Perform linear regression (compute slope and intercept)
    linear_regression.fit(x.reshape(-1, 1), y.reshape(-1, 1))
    intercept = linear_regression.intercept_        # underscore indicates that an attribute is estimated
    slope = linear_regression.coef_                 # underscore indicates that an attribute is estimated

    # Get x and y values to plot the linear fit
    x_vals = np.array([x.min(), x.max()])
    y_vals = intercept + slope * x_vals
    y_vals = np.squeeze(y_vals)                     # change shape from (1,N) to (N,)

    # Compute prediction (pass the regressor as the argument and get the corresponding predicted response)
    # Identical as reg_predictor = slope * x + intercept
    reg_predictor = linear_regression.predict(x.reshape(-1, 1))

    # Compute coefficient of determination R^2 of the prediction
    r2_sc = linear_regression.score(x.reshape(-1, 1), y.reshape(-1, 1))

    return intercept, slope, reg_predictor, r2_sc, x_vals, y_vals


def read_mscc(path_results):
    """
    Read csv files containing normalized metrics generated by sct_compute_compression
    """
    list_files_results = os.listdir(path_results)
    list_subject = list(set([file.split('_')[0] for file in list_files_results]))
    list_subject.sort()
    # Initialize pandas dataFrame where metrics across all subjects will be stored
    mscc_df = pd.DataFrame(columns=metrics_ratio + metrics_ratio_norm)

    # Loop across subjects
    for subject in list_subject:
        # Initialize dict with metrics_ratio and metrics_ratio_norm as keys
        mscc_dict = {metric: [] for metric in metrics_ratio + metrics_ratio_norm}
        # Loop across metrics
        for metric in metrics:
            file = subject + '_acq-ax_T2w_' + metric + '_norm.csv'
            # Read csv file as pandas dataFrame
            df = pd.read_csv(os.path.join(path_results, file), encoding='utf-8')
            # Check if subjects has more than one compression
            if df.shape[0] > 1:
                # Select only row based on 'slice(I->S)' column
                df = df[df['slice(I->S)'] == compression_slice[subject]]
            mscc_dict[metric + '_ratio'] = df[metric + '_ratio'].values[0]
            mscc_dict['normalized_' + metric + '_ratio'] = df['normalized_' + metric + '_ratio'].values[0]
        # Insert mscc_dict into mscc_df as a new row
        mscc_df.loc[subject] = mscc_dict

    return mscc_df


def read_lesion(path_data_processed):
    """
    Read xls files containing lesion volume generated by sct_analyze_lesion
    """
    list_subject = os.listdir(path_data_processed)
    # Ignore .DS_Store
    if '.DS_Store' in list_subject:
        list_subject.remove('.DS_Store')
    list_subject.sort()

    # Initialize pandas dataFrame where lesion volume across all subjects will be stored
    lesion_df = pd.DataFrame(columns=['volume [mm3]'])

    # Loop across subjects
    for subject in list_subject:
        lesion_dict = {'volume [mm3]': []}
        # Construct path to xls file
        file = os.path.join(path_data_processed, subject, 'anat', subject + '_acq-ax_T2w_label-lesion_analysis.xls')
        # Read xls file as pandas dataFrame
        # run 'pip install xlrd' if you get an error
        df = pd.read_excel(file)
        # Sum lesion volume across all lesions
        df = df.sum()
        lesion_dict['volume [mm3]'] = df['volume [mm3]']
        # Insert lesion_dict into lesion_df as a new row
        lesion_df.loc[subject] = lesion_dict

    return lesion_df


def main():
    parser = get_parser()
    args = parser.parse_args()

    # If argument path-out doesn't exists, create it.
    if not os.path.exists(args.path_out):
        os.mkdir(args.path_out)

    # Dump log file there
    if os.path.exists(FNAME_LOG):
        os.remove(FNAME_LOG)
    fh = logging.FileHandler(os.path.join(os.path.abspath(args.path_out), FNAME_LOG))
    logging.root.addHandler(fh)

    mscc_df = read_mscc(args.path_results)
    lesion_df = read_lesion(args.path_data_processed)

    # Drop sub-12 because it has large lesion volume
    mscc_df = mscc_df.drop('sub-12')
    lesion_df = lesion_df.drop('sub-12')

    print('here')
    for metric in metrics:
        # Compute and plot correlation between lesion volume and metric
        corr_ratio = mscc_df[metric + '_ratio'].corr(lesion_df['volume [mm3]'], method='spearman')
        print('Correlation between lesion volume and ' + metric + ' ratio: ' + str(corr_ratio))
        corr_ratio_normalized = mscc_df['normalized_' + metric + '_ratio'].corr(lesion_df['volume [mm3]'], method='spearman')
        print('Correlation between lesion volume and normalized ' + metric + ' ratio: ' + str(corr_ratio_normalized))

        _, _, _, _, x_vals_ratio, y_vals_ratio = compute_regression(lesion_df['volume [mm3]'],
                                                                    mscc_df[metric + '_ratio'])
        _, _, _, _, x_vals_ratio_normalized, y_vals_ratio_normalized = compute_regression(lesion_df['volume [mm3]'],
                                                                                          mscc_df['normalized_' + metric + '_ratio'])
        plt.figure()
        plt.scatter(lesion_df['volume [mm3]'], mscc_df[metric + '_ratio'], color='blue', label=metric + '_ratio')
        plt.scatter(lesion_df['volume [mm3]'], mscc_df['normalized_' + metric + '_ratio'], color='red', label=metric + '_ratio_norm')
        plt.plot(x_vals_ratio, y_vals_ratio, color='blue')
        plt.plot(x_vals_ratio_normalized, y_vals_ratio_normalized, color='red')
        # Add x and y labels
        plt.xlabel('Lesion volume [mm³]')
        plt.ylabel(METRIC_TO_AXIS[metric])
        plt.legend()
        # Add corr_ratio and corr_ratio_normalized to plot
        plt.text(0.05, 0.12, 'Correlation ratio: ' + str(round(corr_ratio, 3)), transform=plt.gca().transAxes)
        plt.text(0.05, 0.05, 'Correlation ratio norm: ' + str(round (corr_ratio_normalized, 3)), transform=plt.gca().transAxes)
        plt.savefig(os.path.join(args.path_out, metric + '_vs_lesion_volume.png'))
        print('Saved: ' + os.path.join(args.path_out, metric + '.png'))


if __name__ == '__main__':
    main()